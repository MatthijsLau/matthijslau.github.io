\documentclass[class = report, crop = false]{standalone}
\usepackage{standalone}

\begin{document}
\chapter{Mathematical Methods of Classical Mechanics}\label{chp: hamiltonian systems}
In this chapter, we shall finally see symplectic geometry and classical mechanics come together and we will show that interpreting Hamiltonian mechanics as a geometric theory leads to some powerful results. To do this, we will first discuss how we let a symplectic form act on a smooth function, where we are again heavily inspired by Riemannian geometry. We will then shortly discuss Hamiltonian systems before diving deeper into the theory in terms of first integrals and integrable systems. We will see that these first integrals, which are the constants of the Hamiltonian flow, generate symmetries of the system and allow us to find Darboux charts that make sense in terms of mechanics. This chapter is mainly based on the ideas from \cite[Chapter 18]{CannasdaSilva2008} and \cite[Chapter 10]{Arnold1989}. Remark that we will only discuss Hamiltonians which do not explicitly depend on time.


\section{Hamiltonian Vector Fields}\label{sec: hamiltonian vector fields}
	We would like to determine some form of movement on a symplectic manifold with just a single smooth function. Normally one encodes movement on a manifold with a vector field, hence, we are looking for a manner of transforming a smooth function into a vector field. In calculus, this is done by using the gradient, hence, we will search for a symplectic equivalent of this, which we will call the Hamiltonian vector field of a function. Let us first consider how one does this on a Riemannian manifold and then replicate this method on symplectic manifolds.
	
	\subsection{Riemannian Gradients}\label{sec: riemannian gradients}
		In Euclidean geometry, we may define the gradient as follows.
		\begin{definition}\label{def: linear gradient}
			Let \(f:\R[n]\to\R\) be a function and \(x\in\R[n]\), if the partial derivates of \(f\) exist at a point \(x\in\R[n]\), define the gradient of \(f\) in \(x = \h{x^1,\ldots,x^n}\) as 
			\begin{equation*}
				\grd f\h{x} = \sum_{i = 1}^n\pdv{f}{x^i}\h{x}\hat{e}_i,
			\end{equation*}
			where \(\hat{e}_i\) denotes the \(i\)-th basis vector of \(\R[n]\).
		\end{definition}
		It should be clear that the gradient takes a smooth function on \(\R[n]\) to a vector field, in this case, a function \(\grd f:\R[n]\to\R[n]\). To generalise this construction to a Riemannian manifold, we consider the naturally defined differential of a function and map it to the tangent bundle using the musical isomorphisms generated by the Riemannian metric.
		\begin{definition}\label{def: gradient}
			Let \(\h{\m,g}\) be a Riemannian manifold and \(f\in\sff\) then define
			\begin{equation*}
				\grd f = \h{df}^\sharp.
			\end{equation*}
			Here, \(\eta^\sharp = \hat{g}^{-1}\h{\eta}\) with \(\hat{g}:\tang\to\cotang\) is the induced map by the metric \(g\).
		\end{definition}
		\begin{remark}
			The isomorphism \(\hat{g}:\tang\to\cotang\) exists on the premise that \(g\) is non-degenerate.
		\end{remark}
		We should check that this is equivalent to the gradient in calculus when working on Euclidean space. In this case we have \(\h{dx^i}^\sharp = \pdv*{x^i}\), such that
		\begin{equation*}
			\grd f = \h{df}^\sharp = \h{\pdv{f}{x^i}dx^i}^\sharp = \sum_{i = 1}^n\pdv{f}{x^i}\h{dx^i}^\sharp = \sum_{i = 1}^n\pdv{f}{x^i}\pdv{x^i}.
		\end{equation*}
		We can then identify \(\rtang[n]\cong\R[n]\) with \(\pdv*{x^i}\mapsto\hat{e}_i\). This shows that this is indeed the vector field we wanted.
	
	\subsection{Symplectic Analogue}\label{sec: symplectic gradient}
		To create a symplectic analogue to the gradient, we should take extra notice of the non-degeneracy of the symplectic form and the Riemannian metric. The existence of the Riemannian gradient was dependent on this non-degeneracy, and hence, we can replicate this construction on symplectic manifolds. We will define the analogue, called a Hamiltonian vector field of a function, implicitly.
		\begin{definition}\label{def: hamiltonian vector field}
			Let \(\h{\m,\omega}\) be a symplectic manifold and \(f\in \sff\). We then define the \textbf{Hamiltonian vector field of \(f\)} as the vector fields \(X_f\) that satisfies \(\iota_{X_f}\omega = df\).
		\end{definition}
		To see that this is the actual symplectic analogue of the gradient, remark that \(\iota_X\omega = \hat{\omega}\h{X}\) and thus \(\hat{\omega}^{-1}\h{df}\) satisfies this condition
		\begin{equation*}
			\iota_{\hat{\omega}^{-1}\h{df}}\omega = df.
		\end{equation*}
		We can ensure the existence and uniqueness through the fact that \(\omega\) is non-degenerate. However, this is not very insightful on the form of the Hamiltonian vector field. Therefore, we will prove the existence and uniqueness in coordinates.
		\begin{proposition}\label{prp: existence hamiltonian vector field}
			For every function \(f\in\sff\), where \(\h{\m,\omega}\) is a symplectic manifold, there exists a unique Hamiltonian vector field, \(X_f\), and in a Darboux chart \(\h{U,\symcor{x}{y}}\) it is given by
			\begin{equation*}
				X_f|_U = \sum_{i = 1}^n\h{\pdv{f}{y^i}\pdv{x^i} - \pdv{f}{x^i}\pdv{y^i}}.
			\end{equation*}
		\end{proposition}
		\begin{proof}
			Suppose that \(\h{\m,\omega}\) is a symplectic \(2n\)-manifold and \(f\in\sff\). We can then solve the equation \(\iota_{X_f}\omega = df\) in a Darboux chart \(\h{U,\symcor{x}{y}}\). To this extent we write \(X_f|_U = \sum_{i = 1}^n\h{X^i_x\pdv*{x^i} + X^i_y\pdv*{y^i}}\) and the differential of \(f\) is then given by \(df|_U = \sum_{i = 1}^n\h{\pdv{f}{x^i}dx^i + \pdv{f}{y^i}dy^i}\). The contraction of \(\omega\) by \(X_f\) can be calculated using Equation~\ref{eq: action of interior}, 
			\begin{equation*}
				\iota_X\omega|_U = \sum_{i = 1}^n\h{X^i_xdx^i - X^i_ydy^i}.
			\end{equation*}
			Setting this equal to the differential \(df|_U\) results in \(2n\) equations of the form
			\begin{equation*}
				X^i_x = \pdv{f}{y^i}\quad\mbox{ and }\quad X^i_y = -\pdv{f}{x^i}.
			\end{equation*}
			Hence, the explicit expression of the Hamiltonian vector field of a function \(f\) in Darboux coordinates is
			\begin{equation}\label{eq: hamiltonian vector field coordinates}
				X_f|_U = \sum_{i = 1}^n\h{\pdv{f}{y^i}\pdv{x^i} - \pdv{f}{x^i}\pdv{y^i}}.
			\end{equation}
			Thus we verified that the Hamiltonian vector field always exists. Furthermore, any Hamiltonian vector field of the function needs to satisfy this expression, implying they are also unique.
		\end{proof}
		\begin{example}
			Take the manifold \(\R[2]\backslash \hv{\h{0,p}:p\in\R}\) with the global chart \(\h{q,p}\) and symplectic form \(\omega = dq\wedge dp\). Consider the smooth function \(f\h{q,p} = \dfrac{1}{2}p^2 - q^{-1}\), notice that \(q\) is never zero hence it is smooth. We can then obtain the Hamiltonian vector field of \(f\) from Equation~\ref{eq: hamiltonian vector field coordinates}.
			\begin{equation*}
				X_f = \pdv{f}{p}\pdv{q} - \pdv{f}{q}\pdv{p} = p\pdv{q} - q^{-2}\pdv{p}.
			\end{equation*}
			We can check whether this is correct by entering it into the formula \(\iota_{X_f}\omega\h{v} = df\h{v}\) for \(v = v^q\pdv*{q} + v^p\pdv*{p}\).
			\begin{align*}
				\iota_{X_f}\omega\h{v}
				&= \omega\h{X_f,v} = dq\wedge dp\h{p\pdv{q} - q^{-2}\pdv{p}, v^q\pdv{q} + v^p\pdv{p}}\\
				&= pv^p + q^{-2}v^q = v^q\pdv{f}{q} + v^p\pdv{f}{p} = df\h{v}.
			\end{align*}
			Thus, \(X_f\) indeed satisfies \(\iota_{X_f}\omega = df\), which implies it is the Hamiltonian vector field of \(f\).
		\end{example}
		We have shown that every function has a unique Hamiltonian vector field, giving us a linear mapping \(\sff\to\vf:f\to X_f\), where the linearity is a direct consequence of Proposition~\ref{prp: contraction linearity}. The question now arises whether this mapping is injective or surjective. The answer to both is no.
		\begin{corollary}\label{cor: differentials equals hamiltonians}
			Two smooth functions on a symplectic manifold have the same Hamiltonian vector field if and only if \(f - g\) is a constant on each connected component of the manifold.
		\end{corollary}
		\begin{proof}
			Take some \(f,g\in\sff\), with \(\h{\m,\omega}\) being a symplectic manifold. Suppose that their Hamiltonian vector fields be equal. We can then conclude that
			\begin{equation*}
				df = \iota_{X_f}\omega = \iota_{X_g}\omega = dg.
			\end{equation*}
			Now suppose that their differentials are equal. Then we can conclude that
			\begin{equation*}
				\iota_{X_f}\omega = df = dg = \iota_{X_g}\omega.
			\end{equation*}
			This implies, together with the uniqueness of Hamiltonian vector fields of functions, that \(X_f = X_g\).
		\end{proof}
		Corollary~\ref{cor: differentials equals hamiltonians} shows that the mapping \(\sff\to\vf:f\mapsto X_f\) induces a well-defined injective mapping \(\sff/Z^0\h{\m}\to\vf:\ha{f}\mapsto X_f\). However, this is still not necessarily a surjection, as we showcase with Example~\ref{exp: not hamiltonian vector field}.
		\begin{example}\label{exp: not hamiltonian vector field}
			Consider the manifold \(\h{S^1\backslash\hv{1}}^2\) and take the global coordinates, \(\h{\theta,\phi}\). We can then define the symplectic form \(\omega_0 = d\theta\wedge d\phi\) and the vector field \(X = \pdv*{\theta}\). We can then calculate that \(\iota_X\omega = d\phi\), implying that \(X\) is the Hamiltonian vector field of \(\phi\).
			
			Suppose that we were able to smoothly extend \(X\) to a Hamiltonian vector field of some function \(\mathbb{T}^2\). Notice that this function can not be \(\phi\)  as this is not defined on the whole of \(\mathbb{T}^2\), hence suppose it is \(f\). If follows that \(df|_{\mathbb{T}^2\backslash\hv{\h{1,1}}} = d\phi\). If we then integrate \(df\) over a closed curve \(\gamma\), Stokes's theorem tells us the integral is \(0\). Meanwhile, take the curve \(\gamma:\ha{0,1}\to\mathbb{T}^2:t\mapsto \h{0,\exp\h{2\pi t}}\). We then calculate
			\begin{equation*}
			\int_{\ha{0,1}}\pull{\gamma}df = \int_{\ha{0,1}}\pull{\gamma}d\phi = \int_{\ha{0,1}}2\pi dt = 2\pi\neq 0.
			\end{equation*}
			Hence, we cannot extend \(X\) to a Hamiltonian vector field.
		\end{example}
		Luckily, we can quite easily determine the range of this mapping, i.e. all the vector fields that are the Hamiltonian vector field of some function.
		\begin{definition}
			A vector field \(X\) on a symplectic manifold \(\h{\m,\omega}\) is called a \textbf{Hamiltonian vector field} if \(\iota_X\omega\) is exact. The set of all Hamiltonian vector fields is denoted by \(\hvf\). The function \(h\in\sff\) such that \(\iota_X\omega = dh\) is called the \textbf{Hamiltonian function of \(X\)}.
		\end{definition}
		It should be clear that these Hamiltonian vector fields are exactly the vector fields that are the Hamiltonian vector field of some function. Furthermore, their flow preserves the structure of our symplectic manifold.
		\begin{proposition}\label{prp: hamiltonian preserve symplectic form}
			The symplectic form of a symplectic manifold is invariant under the flow of a Hamiltonian vector field on that same symplectic manifold.
		\end{proposition}
		\begin{proof}
			Suppose that \(\h{\m,\omega}\) is a symplectic manifold and \(X\) is a Hamiltonian vector field with a Hamiltonian function \(h\). If we rewrite the Lie derivative using Cartan's magic formula, we can use that \(\omega\) is closed and \(\iota_X\omega\) is exact. It then follows that
			\begin{equation*}
				\ld[X]\omega = \h{\iota_X\circ d + d\circ \iota_X}\omega = \iota_X\h{d\omega} + d\h{\iota_X\omega} = \iota_X\h{0} + d\circ d\h{h} = 0.
			\end{equation*}
			This proves that the symplectic form is invariant under the flow of a Hamiltonian vector field.
		\end{proof}
		A well-behaved connection between the Hamiltonian vector fields and smooth functions can be made through their respective bracket algebras, the Lie algebra and the Poisson algebra.
		
		\subsection{Bracket Algebras}\label{sec: bracket algebra}
			This section will focus on the algebraic properties of \(\hvf\) and \(\sff\) and how we connect these through the view of bracket algebras. We will define abstract Lie algebras and Poisson algebras and see their connection with symplectic forms. We can get more grip on the behaviour of the mapping \(\sff\to\hvf:f\to X_f\) through these algebras.
			
			\subsubsection{Lie Algebras}\label{sec: lie algebra}
				It should be of no surprise that the algebraic structure of the Hamiltonian vector fields is familiar to that of vector fields in general, in other words, it has a Lie algebra structure. Let us first define what such a structure entails and then prove that the Hamiltonian vector fields are actually of this form.
				
				\begin{definition}\label{def: lie algebra}
					A \textbf{Lie algebra} is a pair \(\h{\liealg, \comm{\cdot}{\cdot}}\), such that \(\liealg\) is a real vector space and \(\comm{\cdot}{\cdot}:\liealg\times\liealg\to\liealg\) is a bilinear map such that the following hold for all \(x,y,z\in\liealg\)
					\begin{alignat*}{2}
						&\comm{x}{y} = -\comm{y}{x},\\
						&\comm{x}{\comm{y}{z}} + \comm{y}{\comm{z}{x}} + \comm{z}{\comm{x}{y}} = 0.
					\end{alignat*}
					These identities are respectively called skew-symmetry and the Jacobi identity. We call \(\comm{\cdot}{\cdot}\) the \textbf{Lie bracket} of the Lie algebra.
				\end{definition}
				\begin{proposition}\label{prp: vector field algebra}
					The bracket \(\comm{X}{Y} = XY - YX\) defines a Lie bracket on the vector fields, and hence a Lie algebra \(\h{\vf,\comm{\cdot}{\cdot}}\).
				\end{proposition}
				\begin{proof}
					See Corollary~\ref{cor: lie bracket properties}.
				\end{proof}
				As the Hamiltonian vector fields are a subset of the vector fields on a symplectic manifold, we would like to show that it inherits a Lie algebraic structure. In other words, we would like to show that \(\h{\hvf,\comm{\cdot}{\cdot}}\) is a Lie subalgebra of \(\h{\vf,\comm{\cdot}{\cdot}}\). In this proof, we will use the following lemma.
				\begin{lemma}\label{lem: contraction by bracket}
					Let \(X,Y\) be vector fields on \(\m\), then the following holds
					\begin{equation*}
						\iota_{\comm{X}{Y}} = \ld[X]\iota_Y - \iota_Y\ld[X]
					\end{equation*}
				\end{lemma}
				\begin{proof}
					The proof is similar to that of Cartan's magic formula. Once again we can notice that both sides are derivations of \(\Omega\h{\m}\) with degree \(-1\). Hence, if we check the equality on smooth functions and exact \(1\)-forms, we can extend it using induction to an arbitrary \(k\)-form.
					
					Suppose that \(f\in\sff\) and \(X,Y\in\vf\). By then remarking that \(f\) and \(\ld[X] f\) are both \(0\)-forms, it follows from the definition of \(\iota\) that both sides vanish.
					
					Suppose that \(\eta\) is an exact \(1\)-form, hence, there exists a smooth function \(f\in\sff\) such that \(\eta = df\). By using the definitions of the interior multiplication and Lie derivative, and Proposition~\ref{prp: exterior derivative and lie derivative commute}, it follows that
					\begin{align*}
						\iota_{\comm{X}{Y}}\eta
						&= \iota_{\comm{X}{Y}}df = df\h{\comm{X}{Y}} = \comm{X}{Y}f = XYf - YXf = X\h{df\h{Y}} - d\h{Xf}\h{Y}\\
						&= X\h{\iota_Y\h{df}} - \iota_Y\h{d\h{Xf}} = \ld[X]\iota_Y\h{df} - \iota_Y\h{d\h{\ld[X]f}}\\
						&= \ld[X]\iota_Y\h{df} - \iota_Y\ld[X]\h{df} = \h{\ld[X]\iota_Y - \iota_Y\ld[X]}\eta.
					\end{align*}
					Hence, by induction, this shows that \(\iota_{\comm{X}{Y}} = \ld[X]\iota_Y - \iota_Y\ld[X]\).
				\end{proof}
				\begin{proposition}\label{prp: hamiltonian vector fields lie algebra}
					The pair \(\h{\hvf,\comm{\cdot}{\cdot}}\), where \(\comm{\cdot}{\cdot}\) is the Lie bracket on vector fields, defines a Lie algebra.
				\end{proposition}
				\begin{proof}
					Suppose that \(\h{\m,\omega}\) is a symplectic manifold. As \(\comm{\cdot}{\cdot}\) is the Lie bracket on \(\vf\), it is clear that it is bilinear, skew-symmetric and satisfies the Jacobi identity. Furthermore, we can easily show that \(\hvf\) is a real vector space as it is closed under addition and scalar multiplication in \(\vf\). Take arbitrary \(X,Y\in\hvf\) and \(a,b\in\R\), we can then write \(\iota_X\omega = df\) and \(\iota_Y\omega = dg\), it then follows using Propositions~\ref{prp: contraction linearity}~and~\ref{prp: existence exterior derivative manifold} that
					\begin{equation*}
						\iota_{aX + bY}\omega = a\iota_{X}\omega + b\iota_Y\omega = adf + bdg = d\h{af + bg}.
					\end{equation*}
					Thus \(aX + bY\in\hvf\) implying that \(\hvf\) is a real vector space.
					
					We then only need to show that \(\hvf\) is closed under the action of \(\comm{\cdot}{\cdot}\). Take some arbitrary \(X,Y\in\hvf\) and apply Lemma~\ref{lem: contraction by bracket} and Cartan's magic formula.
					\begin{equation}\label{eq: contraction by bracket written out}
						\iota_{\comm{X}{Y}}\omega = \ld[X]\iota_Y\omega - \iota_Y\ld[X]\omega = d\iota_X\iota_Y\omega + \iota_Xd\iota_Y\omega - \iota_Yd\iota_X\omega + \iota_Y\iota_Xd\omega.
					\end{equation}
					The fact that \(\iota_X\omega\), \(\iota_Y\omega\) and \(\omega\) are closed, implies that the last three terms vanish, leaving just the first. Thus, Equation~\ref{eq: contraction by bracket written out} simplifies to
					\begin{equation}\label{eq: contraction by bracket is differential}
						\iota_{\comm{X}{Y}}\omega = d\h{\iota_X\iota_Y\omega} = -d\h{\omega\h{X,Y}}.
					\end{equation}
					Thus \(\iota_{\comm{X}{Y}}\omega\) is exact and \(\comm{X}{Y}\) is a Hamiltonian vector field. Together this implies that \(\h{\hvf,\comm{\cdot}{\cdot}}\) is indeed a Lie algebra.
 				\end{proof}
				
			\subsubsection{Poisson Algebras}\label{sec: poisson algebra}
				Next up, we will introduce Poisson algebras. These are special cases of Lie algebras where we also assume that the space is a commutative associative algebra and compatibility of the algebraic structure with the Lie algebra structure. We will then show that the smooth functions on a symplectic manifold have such a structure.
				\begin{definition}\label{def: poisson algebra}
					A \textbf{Poisson algebra} is a Lie algebra \(\h{\poialg,\acomm{\cdot}{\cdot}}\) such that \(\mathcal{P}\) is a commutative associative algebra over \(\R\) and the bracket satisfies the Leibniz rule.
					\begin{equation*}
						\acomm{f}{gh} = \acomm{f}{g}h + \acomm{f}{h}g.
					\end{equation*}
					The bracket \(\acomm{\cdot}{\cdot}:\mathcal{P}\times\mathcal{P}\to\mathcal{P}\) is called a \textbf{Poisson bracket}.
				\end{definition}
				We will now show that \(\sff\) admits a natural Poisson algebra structure on a symplectic manifold.
				\begin{proposition}\label{prp: symplectic manifold poisson algebra}
					For a symplectic manifold \(\h{\m,\omega}\), the pair \(\h{\sff,\acomm{\cdot}{\cdot}}\) forms a Poisson algebra, with
					\begin{equation*}
						\acomm{\cdot}{\cdot}:\sff\times\sff\to\sff:\h{f,g}\mapsto \omega\h{X_f,X_g},
					\end{equation*}
					where \(X_f\) and \(X_g\) are the Hamiltonian vector fields of \(f\) and \(g\) respectively.
				\end{proposition}
				\begin{proof}
					Let \(\h{\m,\omega}\) be a symplectic manifold and define the bracket \(\acomm{\cdot}{\cdot}\) as in the proposition. It should be clear that \(\sff\) is a commutative associative algebra with pointwise multiplication.
					
					The asymmetry is a consequence of the symplectic form being alternating, such that for \(f,g\in\sff\)
					\begin{equation*}
						\acomm{f}{g} = \omega\h{X_f,X_g} = -\omega\h{X_g,X_f} = -\acomm{g}{f}.
					\end{equation*}
					To prove the bilinearity, we only need to do it in the first component as the second component then follows with the asymmetry. By the linearity of the mapping \(f\mapsto X_f\), we find that
					\begin{align*}
						\acomm{af + bg}{h}
						&= \omega\h{X_{af + bg},X_h} = \omega\h{aX_f + bX_g,X_h}\\
						&= a\omega\h{X_f,X_h} + b\omega\h{X_g,X_h} = a\acomm{f}{h} + b\acomm{g}{h}.
					\end{align*}
					To prove the Jacobi identity we will use the fact that \(\omega\) is closed. Remark the following relation between the symplectic form and Hamiltonian vector fields:
					\begin{equation}\label{eq: poisson bracket as vector field}
						\omega\h{X_f,Y} = \h{\iota_{X_f}\omega}\h{Y} = df\h{Y} = Yf.
					\end{equation}
					It follows from the definition of the bracket that \(\acomm{f}{g} = X_gf\). We can then calculate the action of \(d\omega\) on three vector fields using Proposition 14.32 in \cite{Lee2013} and Equation~\ref{eq: poisson bracket as vector field}. For some arbitrary functions \(f,g,h\in\sff\) we find
					\begin{align*}
						0
						&= d\omega\h{X_f,X_g,X_h} = X_f\omega\h{X_g,X_h} - X_g\omega\h{X_f,X_h} + X_h\omega\h{X_f,X_g}\\
						&\qquad - \omega\h{\comm{X_f}{X_g},X_h} + \omega\h{\comm{X_f}{X_h},X_g} - \omega\h{\comm{X_g}{X_h},X_f}.
					\end{align*}
					If we then set \(\RN{1}\h{X_f,X_g,X_h} = X_f\omega\h{X_g,X_h} - X_g\omega\h{X_f,X_h} + X_h\omega\h{X_f,X_g}\), we can deduce that
					\begin{align*}
						\RN{1}\h{X_f,X_g,X_h}
						&= X_f\omega\h{X_g,X_h} - X_g\omega\h{X_f,X_h} + X_h\omega\h{X_f,X_g}\\
						&= X_f\acomm{g}{h} - X_g\acomm{f}{h} + X_h\acomm{f}{g}\\
						&= \acomm{\acomm{g}{h}}{f} - \acomm{\acomm{f}{h}}{g} + \acomm{\acomm{f}{g}}{h}\\
						&= -\acomm{f}{\acomm{g}{h}} - \acomm{g}{\acomm{h}{f}} - \acomm{h}{\acomm{f}{g}}.
					\end{align*}
					If we also take \(\RN{2}\h{X_f,X_g,X_h} = - \omega\h{\comm{X_f}{X_g},X_h} + \omega\h{\comm{X_f}{X_h},X_g} - \omega\h{\comm{X_g}{X_h},X_f}\), it follows that
					\begin{align*}
						\RN{2}\h{X_f,X_g,X_h}
						&= -\omega\h{\comm{X_f}{X_g},X_h} + \omega\h{\comm{X_f}{X_h},X_g} - \omega\h{\comm{X_g}{X_h},X_f}\\
						&= \omega\h{X_h,\comm{X_f}{X_g}} - \omega\h{X_g,\comm{X_f}{X_h}} + \omega\h{X_f,\comm{X_g}{X_h}}\\
						&= \comm{X_f}{X_g}h - \comm{X_f}{X_h}g + \comm{X_g}{X_h}f\\
						&= X_fX_gh - X_gX_fh - X_fX_hg + X_hX_fg + X_gX_hf - X_hX_gf\\
						&= X_f\acomm{h}{g} - X_g\acomm{h}{f} - X_f\acomm{g}{h} + X_h\acomm{g}{f} + X_g\acomm{f}{h} - X_h\acomm{f}{g}\\
						&= \acomm{\acomm{h}{g}}{f} - \acomm{\acomm{h}{f}}{g} - \acomm{\acomm{g}{h}}{f} + \acomm{\acomm{g}{f}}{h} + \acomm{\acomm{f}{h}}{g} - \acomm{\acomm{f}{g}}{h}\\
						&= \acomm{f}{\acomm{g}{h}} + \acomm{g}{\acomm{h}{f}} + \acomm{f}{\acomm{g}{h}} + \acomm{h}{\acomm{f}{g}} + \acomm{g}{\acomm{h}{f}} + \acomm{h}{\acomm{f}{g}}\\
						&= 2\acomm{f}{\acomm{g}{h}} + 2\acomm{g}{\acomm{h}{f}} + 2\acomm{h}{\acomm{f}{g}}.
					\end{align*}
					Hence, it follows from the fact that \(0 = d\omega\h{X_f,X_g,X_h} = \RN{1}\h{X_f,X_g,X_h} + \RN{2}\h{X_f,X_g,X_h}\) that
					\begin{align*}
						0
						&= -\acomm{f}{\acomm{g}{h}} - \acomm{g}{\acomm{h}{f}} - \acomm{h}{\acomm{f}{g}} + 2\acomm{f}{\acomm{g}{h}} + 2\acomm{g}{\acomm{h}{f}} + 2\acomm{h}{\acomm{f}{g}}\\
						&= \acomm{f}{\acomm{g}{h}} + \acomm{g}{\acomm{h}{f}} + \acomm{h}{\acomm{f}{g}}.
					\end{align*}
					This proves that the Jacobi identity holds. Moreover, Equation~\ref{eq: poisson bracket as vector field} implies the bracket satisfies the product rule. Take arbitrary \(f,g,h\in\sff\), then by Proposition~\ref{prp: vector field is derivation}
					\begin{equation*}
						\acomm{f}{gh} = -X_f\h{gh} = -\h{X_fh}g - \h{X_fg}h = \acomm{f}{h}g + \acomm{f}{g}h.
					\end{equation*}
					We can conclude that \(\h{\sff,\acomm{\cdot}{\cdot}}\)is a Poisson algebra, where the bracket is defined by the symplectic form.
				\end{proof}
				\begin{proposition}
					On a symplectic manifold \(\h{\m,\omega}\), the induced Poisson bracket is given locally in Darboux coordinates \(\h{U,\symcor{x}{y}}\) by
					\begin{equation}\label{eq: poisson bracket darboux}
						\acomm{f}{g}|_U = \sum_{i = 1}^n\pdv{f}{x^i}\pdv{g}{y^i} - \pdv{f}{y^i}\pdv{g}{x^i}.
					\end{equation}
				\end{proposition}
				\begin{proof}
					Suppose that \(\h{\m,\omega}\) is a symplectic manifold and \(\h{U,\symcor{x}{y}}\) are some Darboux coordinates. The result follows from a calculation in coordinates where we use the coordinate expression of Hamiltonian vector fields of Equation~\ref{eq: hamiltonian vector field coordinates} and the fact that \(\acomm{f}{g} = X_gf\) as we mentioned in the proof of Proposition~\ref{prp: symplectic manifold poisson algebra}
					\begin{align*}
						\acomm{f}{g}|_U
						&= X_g|_Uf = \h{\sum_{i = 1}^n\pdv{g}{y^i}\pdv{x^i} - \pdv{g}{x^i}\pdv{y^i}}f = \sum_{i = 1}^n\pdv{f}{x^i}\pdv{g}{y^i} - \pdv{f}{y^i}\pdv{g}{x^i}.
					\end{align*}
					This was the exact expression we wanted.
				\end{proof}
			\subsubsection{Combining Bracket Algebras}
				We have seen that a symplectic manifold induces a Lie algebra, \(\h{\hvf,\comm{\cdot}{\cdot}}\), and a Poisson algebra, \(\h{\sff,\acomm{\cdot}{\cdot}}\). The connection between both is by the algebra anti-homomorphism created by taking the Hamiltonian vector field of a function.
				\begin{proposition}\label{prp: algebra anti homomorphism}
					Given a symplectic manifold \(\h{\m,\omega}\), we have an induced Lie algebra anti-homomorphism, \(\sff\to\hvf:h\mapsto X_h\), with \(\acomm{\cdot}{\cdot}\rightsquigarrow-\comm{\cdot}{\cdot}\).
				\end{proposition}
				\begin{proof}
					Suppose that \(\h{\m,\omega}\) is a symplectic manifold. We then have an induced map \(\sff\to\hvf:f\mapsto X_f\). To prove that this map is a Lie algebra anti-homomorphism, we argue it is enough to check whether
					\begin{equation*}
						\iota_{X_{\acomm{f}{g}}}\omega = -\iota_{\comm{X_f}{X_g}}\omega.
					\end{equation*}
					This is a consequence of the unicity of Hamiltonian vector fields and linearity of the interior multiplication in \(X\).
					
					We can then rewrite \(\iota_{\comm{X_f}{X_g}}\omega\) if by using Equation~\ref{eq: contraction by bracket is differential} and get our result.
					\begin{equation*}
						\iota_{\comm{X_f}{X_g}}\omega = -d\h{\omega\h{X_f,X_g}} = -d\acomm{f}{g} = -\iota_{X_{\acomm{f}{g}}}\omega.
					\end{equation*}
					This proves \(X_{\acomm{f}{g}} = -\comm{X_f}{X_g}\) and thus that the map is an anti-homomorphism of Lie algebras.
				\end{proof}

\section{Hamiltonian Systems}
	Now that we have seen the interplay between symplectic forms, smooth functions and vector fields, we can build their relation to physics. We will use symplectic manifolds in combination with a smooth function to create a model of classical physics, more specifically Hamiltonian mechanics. Such a triplet of a manifold, symplectic form and smooth function is what we will call a Hamiltonian system and it is what we will use to model classical mechanics.
	\begin{definition}\label{def: hamiltonian system}
		A \textbf{Hamiltonian system} is a triplet \(\h{\m,\omega,\ham}\). Such that \(\h{\m,\omega}\) is a symplectic manifold and \(\ham\in \sff\) which is called the \textbf{Hamiltonian}. The associated Hamiltonian vector field \(X_{\ham}\) is called the \textbf{Hamiltonian phase flow} and its integral curves are called \textbf{trajectories}.
	\end{definition}
	Using these systems, we can quite easily recover the Hamiltonian equations. Suppose we have some Hamiltonian system \(\h{\m,\omega,\ham}\) and Darboux coordinates \(\h{U,\symcor{x}{y}}\). We see that a trajectory of the system \(\gamma\h{t} = \h{x^i\h{t},y^i\h{t}}\) satisfies
	\begin{equation*}
		\dot{x}^i\h{t} = \pdv{\ham}{y^i}\h{x,y}\quad\mbox{and}\quad\dot{y}^i\h{t} = -\pdv{\ham}{x^i}\h{x,y}.
	\end{equation*}
	These are equivalent to Hamilton's equations we saw in Section~\ref{sec: hamiltonian}. Let us showcase how we model physical systems using this method. In this method, we will most often consider a configuration space, \(\m\), and then take the cotangent bundle with the canonical symplectic form as the symplectic form. This gives a clear distinction between position, the coordinates on \(\m\), and the moment, the coordinates in the cotangent spaces. When setting up a Hamiltonian system as a model, we can still derive the Hamiltonian from the Lagrangian using a Legendre transform. In this case, the Lagrangians are defined as functions on the tangent bundle of the configuration space. The Legendre transform can then locally, at a point, transform the Lagrangian to a Hamiltonian, see \cite[Chapter 20]{CannasdaSilva2008} for a rigorous construction of the Legendre transform. Here, we will work in coordinates, in which case the construction of Section \ref{sec: hamiltonian} is sufficient. Let us consider some simple examples using Hamiltonian systems as a model.
	\begin{example}\label{exp: free body}
		\input{example/freebody.tex}
	\end{example}
	\begin{example}\label{exp: electromagnetic}
		\input{example/electromagnetic.tex}
	\end{example}
%	\begin{example}
%		\input{example/doublependulum.tex}
%	\end{example}

\section{Conserved Quantities}
	The last section introduced our basic model for classical physics: Hamiltonian systems. We will now investigate a special class of functions which are conserved over the trajectories of the system.
	\begin{definition}
		An \textbf{first integral}, also called a \textbf{conserved quantity} or \textbf{integral of motion}, of a Hamiltonian system \(\h{\m,\omega,\ham}\) is a function \(f\in\sff\) that is constant along all trajectories of the system.
	\end{definition}
	It can be quite cumbersome to check this condition, as one would need to know the exact flow of the Hamiltonian phase flow. Luckily, we can use the connection between \(\sff\) and the Hamiltonian vector fields to get an easier check for first integrals.
	\begin{proposition}\label{prp: first integral hamiltonian commute}
		If \(\h{\m,\omega,\ham}\) is a Hamiltonian system, then a function \(f\in\sff\) is a first integral of the system if and only if \(\acomm{f}{\ham} = 0\).
	\end{proposition}
	\begin{proof}
		Let \(\h{\m,\omega,\ham}\) be an Hamiltonian system and \(f\in\sff\). Using Proposition~\ref{prp: lie derivative flow commute} and Equation~\ref{eq: poisson bracket as vector field}, we deduce that the change of \(f\) along the flow is given by
		\begin{equation*}
			\dtnull[t_0]\h{f\circ\timeflow[X_{\ham}]{t}} = \pulltimeflow[X_{\ham}]{t_0}\ld[X_{\ham}]f = \pulltimeflow[X_{\ham}]{t_0}\iota_{X_{\ham}}df = \pulltimeflow[X_{\ham}]{t_0}\acomm{f}{\ham}.
		\end{equation*}
		This proves the equivalence of the two statements.
	\end{proof}
	Using Proposition~\ref{prp: first integral hamiltonian commute}, we can easily verify whether a function is a first integral of a system.
	\subsection{Symmetries}
		We will show that these first integrals give quite a lot of information about the physical system in terms of symmetries. Here a symmetry of a Hamiltonian system is defined as an infinitesimal symmetry, i.e. a vector field under whose flow the Hamiltonian and symplectic form are invariant.
		\begin{definition}\label{def: infinitesimal symmetry}
			A vector field is an \textbf{infinitesimal symmetry} of a Hamiltonian system \(\h{\m,\omega,\ham}\) if both \(\omega\) and \(\ham\) are invariant under its flow.
		\end{definition}
		\begin{lemma}\label{lem: inf sym}
			A vector field \(X\) is an infinitesimal symmetry of \(\h{\m,\omega,\ham}\) if and only if \(X\ham = 0\) and \(\iota_X\omega\) is closed.
		\end{lemma}
		\begin{proof}
			Let \(X\) be a vector field on a Hamiltonian system, \(\h{\m,\omega,\ham}\). Suppose that \(X\) is an infinitesimal symmetry of the Hamiltonian system, then by Theorem 12.37 in \cite{Lee2013} we know that the invariance under the flow is equivalent to
			\begin{equation}\label{eq: invariance under flow}
				\ld[X]{\omega} = 0 = \ld[X]\ham.
			\end{equation}
			We can easily calculate the action of \(X\) on a Hamiltonian system by the definition of the Lie derivative on smooth functions and Equation~\ref{eq: invariance under flow}.
			\begin{equation*}
				X\ham = \ld[X]\ham = 0.
			\end{equation*}
			Furthermore, as the symplectic form is closed we can rewrite \(d\circ\iota_X\omega\) to a Lie derivative using Cartan's magic formula, such that
			\begin{equation*}
				d\circ\iota_X\omega = \h{d\circ\iota_X + \iota_X\circ d}\omega = \ld[X]\omega = 0.
			\end{equation*}
			This shows the implication one way. For the other way, suppose that \(X\ham = 0\) and \(\iota_X\omega\) is closed. Calculate the Lie derivative of \(\ham\) along \(X\)
			\begin{equation*}
				\ld[X]\ham = \h{d\circ\iota_X + \iota_X\circ d}\ham = d\ham\h{X} = Xh = 0.
			\end{equation*}
			Thus \(\ham\) is invariant under the flow of \(X\). As for \(\omega\), we can do a similar calculation and use the fact that \(\omega\) and \(\iota_X\omega\) are both closed
			\begin{equation*}
				\ld[X]\omega = \h{d\circ\iota_X + \iota_X\circ d}\omega = d\h{\iota_X\omega} = 0.
			\end{equation*}
			This shows that the implication holds the other way as well.
		\end{proof}
		We will now show that there is a correspondence between the first integrals of a Hamiltonian system and the possible infinitesimal symmetries. This is a variation of Noether's theorem, which is most often stated in terms of moment maps and Lie group actions, see Chapter 24 in \cite{CannasdaSilva2008}. The following theorem in terms of infinitesimal symmetries is Theorem 22.22 in \cite{Lee2013}
		\begin{theorem}
			Let \(\h{\m,\omega,\ham}\) be a Hamiltonian system. If \(f\) is a first integral of the system, then its Hamiltonian vector field is an infinitesimal symmetry of the system. Furthermore, if all closed \(1\)-forms are exact, then all infinitesimal symmetries are generated as the Hamiltonian vector field of some function, which is unique up to some function that is constant on each component.
		\end{theorem}
		\begin{proof}
			Let \(\h{\m,\omega,\ham}\) be a Hamiltonian system and \(f\in\sff\) a first integral of this system. The Hamiltonian is invariant under the flow of \(X_f\) by definition and \(\omega\) is invariant under the flow of any Hamiltonian vector field, see Proposition~\ref{prp: hamiltonian preserve symplectic form}.
			
			Now suppose that all closed \(1\)-forms on \(\m\) are exact and let \(X\) be an infinitesimal symmetry of \(\h{\m,\omega,\ham}\). If follows from Lemma~\ref{lem: inf sym} that \(X\ham = 0\) and that \(\iota_X\omega\) is closed. By assumption, this form is also exact and hence there is a function \(f\) such that \(X = X_f\). We can then easily deduce that it commutes with the Hamiltonian
			\begin{equation*}
				\acomm{\ham}{f} = X_f\ham = X\ham = 0.
			\end{equation*}
			Thus \(f\) is a first integral of the Hamiltonian system. Remark that \(f\) is defined uniquely up to some element of \(Z^0\h{\m}\) as in Proposition~\ref{cor: differentials equals hamiltonians}.
		\end{proof}
		\begin{example}
			Let us describe a spherical pendulum. This consists of a rigid rod of unit length and negligible mass which has one point fixed in space around which it is free to rotate. An object of unit mass is attached to the other end of the rod and is under the influence of a constant gravitational field, whose acceleration constant we set to \(1\). No other external forces are acting on the system. The position of the object can then be described as a point on \(\mathbb{S}^2\), which is therefore the configuration space. The phase space is then given by \(\h{\cotang[\mathbb{S}^2],\omega_{\can}}\).
			
			In Cartesian coordinates, we can describe the Lagrangian as
			\begin{equation*}
				\lag\h{x,y,z,\dot{x},\dot{y},\dot{z}} = \dfrac{\dot{x}^2 + \dot{y}^2 + \dot{z}^2}{2} - z.
			\end{equation*}
			We can transform these to the more natural coordinates \(\theta\) and \(\phi\) by the usual spherical coordinate transformation,
			\begin{align*}
				&x = \sin\h{\theta}\cos\h{\phi}, &&\dot{x} = \cos\h{\theta}\cos\h{\phi}\dot{\theta} - \sin\h{\theta}\sin\h{\phi}\dot{\phi}\\
				&y = \sin\h{\theta}\sin\h{\phi}, &&\dot{y} = \cos\h{\theta}\sin\h{\phi}\dot{\theta} + \sin\h{\theta}\cos\h{\phi}\dot{\phi}\\
				&z = \cos\h{\theta}, &&\dot{z} = -\sin\h{\theta}\dot{\theta}.
			\end{align*}
			Using this transformation, we can write the Lagrangian and the associated general momenta as
			\begin{equation*}
				\lag\h{\theta,\phi,\dot{\theta},\dot{\phi}} = \dfrac{\dot{\theta}^2 + \sin^2\h{\theta}\dot{\phi}^2}{2} - \cos\h{\theta},\quad p_\theta = \pdv{\lag}{\dot{\theta}} = \dot{\theta},\quad p_\phi = \pdv{\lag}{\dot{\phi}} = \sin^2\h{\theta}\dot{\phi}.
			\end{equation*}
			This lets us determine the Hamiltonian as
			\begin{equation*}
				\ham\h{\theta,\phi,p_\theta,p_\phi} = p_\theta\dot{\theta} + p_\phi\dot{\phi} - \lag = \dfrac{p_\theta^2 + \csc^2\h{\theta}p_\phi^2}{2} + \cos\h{\theta}.
			\end{equation*}
			Now take the function \(J = p_\phi\), we can deduce that this is a first integral of the system using Proposition~\ref{prp: first integral hamiltonian commute} and the fact that the Poisson bracket is given by Equation~\ref{eq: poisson bracket darboux}
			\begin{equation*}
				\acomm{\ham}{J} = \pdv{\ham}{\theta}\pdv{J}{p_\theta} - \pdv{\ham}{p_\theta}\pdv{J}{\theta} + \pdv{\ham}{\phi}\pdv{J}{p_\phi} - \pdv{\ham}{p_\phi}\pdv{J}{\phi}.
			\end{equation*}
			As \(J\) is only dependent on \(p_\phi\) and \(\ham\) is independent of \(\phi\), it follows that \(\acomm{\ham}{J} = 0\) and thus \(J\) is a first integral of the Hamiltonian system.
		\end{example}
	\subsection{Integrable Systems}
		Next up, we will research the solvability of a system depending on the first integrals. We already saw that we were able to find the Hamiltonian phase flow of some systems, see Examples~\ref{exp: free body} and~\ref{exp: electromagnetic}, but we could not always easily solve these equations. We will see that a system is solvable if sufficient and well-behaved first integrals exist. We will see that we can find suitable coordinates on such systems in which the motions are trivial and that the coordinates can be constructed by quadratures. In this section, we will follow Chapter 10 of \cite{Arnold1989}, however, more general theorems are also found in Chapter 18 of \cite{CannasdaSilva2008}.
		\begin{definition}
			A Hamiltonian system \(\h{\m,\omega,\ham}\) is called an \textbf{integrable system} if there exist \(n = \frac{1}{2}\dim\m\) first integrals, \(f_1 = \ham,f_2,\ldots,f_n\), that commute, \(\acomm{f_i}{f_j} = 0\) for all \(i\) and \(j\), and have linearly independent differentials. Such a system is denoted as \(\h{\m,\omega,f}\), where \(f = \h{\ham,f_2,\ldots,f_n}\). We abbreviate the flow of the Hamiltonian vector field of \(f_i\) as \(\flow[X_{f_i}] = \flow[i]\) and also abbreviate \(\posflow[X_{f_i}]{p} = \posflow[i]{p}\) and \(\timeflow[X_{f_i}]{t} = \timeflow[i]{t}\).
		\end{definition}
		\begin{remark}
			In some other texts, \cite{CannasdaSilva2008} for example, the differentials of an integrable system are required to be linearly independent on a dense subset instead of the whole manifold. Here, we follow \cite{Arnold1989} which defines them to be linearly independent everywhere.
		\end{remark}
		Given an integrable system, we would like to show that we can determine the trajectories of the Hamiltonian system. To do this, we will consider the following level sets of \(f\),
		\begin{equation*}
			\m_c = f^{-1}\h{c} = \hv{p\in\m:\ \forall i\ f_i\h{p} = c_i}.
		\end{equation*}
		Remark that this is a regular level set as \(f\) has a non-singular differential. This set has some nice properties.
		\begin{proposition}\label{prp: level set is invariant under flow}
			Let \(\h{\m,\omega,f}\) be an integrable system, then \(\m_c\) is a smooth manifold that is invariant under the flow of any of the first integrals.
		\end{proposition}
		\begin{proof}
			It is clear that \(\m_c\) is a manifold as it is a regular level set of \(f\). Furthermore, we know that any first integral \(f_i\) is invariant under the flow of another \(f_j\), and thus for any \(p\in\m_c\), we can deduce that
			\begin{equation*}
				f_i\h{\timeflow[j]{t}\h{p}} = \pulltimeflow[j]{t}f_i\h{p} = f_i\h{p} = c_i.
			\end{equation*}
			This implies that \(\timeflow[j]{t}:\m_c\to\m_c\), and thus that \(\m_c\) is invariant under the flow of the first integrals.
		\end{proof}
		As the flows of all the first integrals commute, we can sometimes define a general global flow of an integrable system.
		\begin{definition}\label{def: global flow}
			If \(\h{\m,\omega,f}\) is an integrable system for which the Hamiltonian vector fields of each first integral are complete on \(\m_c\), we define the \textbf{simultaneous global flow} on \(\m_c\) as
			\begin{equation*}
				\gflow:\R[n]\times\m_c\to\m_c:\h{t,p}\mapsto \h{\timeflow[1]{t_1}\circ\cdots\circ\timeflow[n]{t_n}}\h{p}.
			\end{equation*}
			We then also define \(\gposflow{p}:\R[n]\to\m_c:t\mapsto \gflow\h{t,p}\) and \(\gtimeflow{t}:\m_c\to\m_c:p\mapsto \gflow\h{t,p}\), similar to \(\posflow{t}\) and \(\timeflow{t}\) in Definition~\ref{def: flow}.
		\end{definition}
		By examining the behaviour of this flow we can uncover more information about the level set. We will focus our attention on level sets that are compact and connected as these are of physical interest. However, many results can be generalised to any system as long as all the flows are complete, as this ensures the existence of the simultaneous flow, see \cite{CannasdaSilva2008} for more details on this.
		\begin{lemma}\label{lem: sim flow surjective}
			Let \(\h{\m,\omega,f}\) be an integrable system and \(\m_c\) is compact and connected, then the simultaneous flow \(\gposflow{p}\) is surjective, but not injective.
		\end{lemma}
		\begin{proof}
			Suppose we have some integrable system \(\h{\m,\omega,f}\) and some level set \(\m_c\) which is compact and connected. Remark that the flows of the first integrals then act on a compact manifold and are therefore complete. We can thus define the simultaneous flow \(\gflow\) and let us fix some \(p_0\in\m_c\). Remark that \(\gposflow{p_0}\) can not be a bijection as it is continuous, \(\R[n]\) is Hausdorff but not compact, and \(\m_c\) is compact. If it was a bijection, this would imply it is a homeomorphism such that \(\R[n]\) would be compact. Hence, it is enough to show that \(\gposflow{p_0}\) is surjective.
			
			Firstly, we will show that we can take some small steps using \(\gposflow{p}\) for any \(p\in\m\) to somewhere in the neighbourhood of \(p\). Remark that \(d\gposflow{p}\) is non-singular as the differentials of the first integrals are linearly independent. Hence, by the inverse function theorem, there exist some neighbourhoods \(V\subset\m_c\) and \(U\subset\R[n]\) such that \(\hs{\gposflow{p}|_{U}}^{-1}:V\to U\) exists and defines a chart. For any \(q\in V\) we can then define \(t = \hs{\gposflow{p}|_{U}}^{-1}\h{q}\) such that
			\begin{equation*}
				\gposflow{p}\h{t} = \gposflow{p}\circ\h{\gposflow{p}|_{U}}^{-1}\h{q} = q.
			\end{equation*}
			Suppose that \(q\) is an arbitrary point on \(\m_c\). We know by the connectedness of \(\m_c\) that there exists a continuous path \(\gamma:\ha{0,1}\to\m_c\) such that \(\gamma\h{0} = p_0\) and \(\gamma\h{1} = q\). Because \(\gamma\h{\ha{0,1}}\) is compact, we can find \(\hv{p_i}_{i = 0}^n\), with \(p_n = q\), such that for each \(p_i\) there exists a neighbourhood \(V_i\subset\m_c\) of \(p\) and neighbourhood \(U_i\subset\R[n]\) of \(0\), such that \(\gposflow{p_i}|_{U_i}:U_i\to V_i\) is a diffeomorphism. Furthermore, we can assume that \(V_{i - 1}\cap V_i\neq\emptyset\). See Figure~\ref{fig: covering of path} for a visualisation of this process. Let us now choose some points \(\hv{x_i}_{i = 0}^{m + 1}\), such that \(x_0 = p_0\), \(x_i\in V_{i - 1}\cap V_{i}\) and \(x_{m + 1} = q\in V_m\).
			
			We can then step from \(x_i\) to \(x_{i + 1}\) by using the flow of \(p_i\). Let us define a time step in \(U_i\) as \(t_i = \hs{\gposflow{p_i}}^{-1}\h{x_{i + 1}} - \hs{\gposflow{p_i}}^{-1}\h{x_i}\), such that
			\begin{equation*}
				\gposflow{x_i}\h{t_i} = \gposflow{x_i}\h{\hs{\gposflow{p_i}}^{-1}\h{x_{i + 1}} - \hs{\gposflow{p_i}}^{-1}\h{x_i}} = x_{i + 1}.
			\end{equation*}
			Hence, we can walk from \(x_i\) to \(x_{i + 1}\) with a time step \(t_i\). If we then add all of these steps together, \(t = \sum_{i = 0}^mt_i\), we see that this lets us walk from \(x_0 = p_0\) to \(x_{m + 1} = q\) using \(\gposflow{p_0}\). This implies that there exists some \(t\) such that \(\gposflow{p_0}\h{t} = q\), and thus that \(\gposflow{p_0}\) is surjective.
			\begin{figure}
				\centering
				\includegraphics{img/coverpath.pdf}
				\caption{Here an example of the path connecting two points \(p_0\) and \(p\) and how we cover this. Here, we also see how \(\h{\gposflow{p_2}|_{U_2}}^{-1}\) maps elements from \(V_2\) to \(U_2\). Here, an element mapped by \(\h{\gposflow{p_2}|_{U_2}}^{-1}\) is denoted with a hat. We could also draw \(t_2\) as the vector between \(\hat{x}_2\) and \(\hat{x}_3\).}
				\label{fig: covering of path}
			\end{figure}
		\end{proof}
		\begin{theorem}\label{thm: level set donut}
			Let \(\h{\m,\omega,f}\) be an integrable system. If \(\m_c\) is compact and connected, then \(\m_c\) is diffeomorphic to \(\mathbb{T}^n\).
 		\end{theorem}
 		\begin{proof}
 			Let \(\h{\m,\omega,f}\) be an integrable system such that \(\m_c\) is compact and connected and take some \(p\in\m_c\). By Lemma~\ref{lem: sim flow surjective} we know that \(\gposflow{p}\) is not injective, such that we can consider its stable points defined as
 			\begin{equation*}
 				\Gamma\h{p} = \hv{t\in\R[n]:\ \gposflow{p}\h{t} = p}.
 			\end{equation*}
			We can easily check that this is a subgroup of \(\R[n]\) as the simultaneous flow is also a one-parameter group action. Furthermore, we can prove that it is independent of \(p\). Given any \(q\in\m_c\), we know there is some \(s\in\R[n]\) such that \(\gposflow{p}\h{s} = q\). Thus, for any \(t\in \Gamma\h{p}\) we deduce that
			\begin{equation*}
				\gtimeflow{t}\h{q} = \gtimeflow{t}\circ\gtimeflow{s}\h{p} = \gtimeflow{s}\circ\gtimeflow{t}\h{p} = \gtimeflow{s}\h{p} = q.
			\end{equation*}
			This implies that \(\Gamma\h{p} = \Gamma\h{q}\), such that we can define some unique \(\Gamma\) associated with \(\gflow\). This \(\Gamma\) has the structure of a discrete subgroup of \(\R[n]\). In other words, any point in \(\Gamma\) has a neighbourhood in the subspace topology which only contains itself.
			
			We will first show the existence of such a neighbourhood around \(0\in\Gamma\) and we will use translations of this neighbourhood to show that it works for any \(t\in\Gamma\). First choose an arbitrary \(p\in\m_c\), as \(\gposflow{p}\h{0} = \id\) we know that \(0\in \Gamma\). Now suppose \(U\) is a neighbourhood on which \(\gposflow{p}|_U\) is a diffeomorphism. For an arbitrary \(s\in U\cap\Gamma\) we know that \(\gposflow{p}|_U\h{s} = p_0 = \gposflow{p}|_U\h{0}\) as \(s\in \Gamma\). By the injectivity of \(\gposflow{p}|_U\) it follows that \(s = 0\) and thus \(U\cap\Gamma = \hv{0}\). We can generalise this to any element of \(\Gamma\) by translating it using the flow. Take an arbitrary \(t\in\Gamma\) and define \(q = \gposflow{p}\h{t}\). We can then use the same neighbourhood \(U\) of \(0\) such that \(\gposflow{q}|_U\) is a diffeomorphism and \(U\cap\Gamma = \hv{0}\). This neighbourhood can be transformed back to a neighbourhood around \(t\) using \(\hs{\gposflow{p}}^{-1}\circ\gposflow{q}\). This shows that \(\Gamma\) is a discrete subgroup of \(\R[n]\) and remark that we could choose a single neighbourhood \(U\) such that each \(t\in\Gamma\) satisfies \(\h{t + U}\cap\Gamma = \hv{t}\).
			
			We can now show that this group is generated by some basis \(\hv{e_1,\ldots, e_k}\) such that any element of \(\Gamma\) is a unique integral linear combination of this basis. If \(\Gamma = \hv{0}\), this would be trivial, else we can take a \(x_1\in\Gamma\) such that \(x_1 \neq 0\). Consider the set \(\Delta_1 = \hv{t\in\R[n]:\norm{t}\leq \norm{x_1}}\). Remark that we showed that there exists some neighbourhood \(U\) of \(0\) such that \(\h{t + U}\cap\Gamma = \hv{t}\). Hence, any element \(t\in\Delta_1\cap\Gamma\) is covered by \(t + U\) and as the volume of \(\Delta_1\) is finite, we can conclude that \(\Delta_1\cap\Gamma\) only contains finite elements. We can then choose \(e_1\in\R x_1\backslash\hv{0}\) such that it closest to \(0\). Let us show that \(\mathbb{Z} e_1 = \Gamma\cap\R x_1\). Suppose this is not the case, hence, there exists some \(u_1 \in\h{\Gamma\cap\R x_1}\backslash\mathbb{Z}e_1\). Then there must also exists some \(m\in\mathbb{Z}\) such that \(u_1\in \hv{\h{m + t}e_1:\ t\in\h{0,1}}\), i.e. there exists some \(t\in\h{0,1}\) and \(m\in\mathbb{Z}\) such that \(u_1 = \h{m + t}e_1\). It then follows for these \(t\) and \(m\) that
			\begin{equation*}
				\norm{u_1 - me_1} = \norm{\h{m + t}e_1 - me_1} = \norm{te_1} = t\norm{e_1}.
			\end{equation*}
			As \(t\in\h{0,1}\) it follows that \(u_1 - me_1\) is closer to \(0\) than \(e_1\) but is also not the zero vector. This is a contradiction with the construction of \(e_1\) and thus we can conclude that \(\mathbb{Z}e_1 = \Gamma\cap\R x_1\).
			
			If \(\mathbb{Z}e_1 = \Gamma\) we are done, else we can choose an \(x_2\in\Gamma\backslash\mathbb{Z}e_1\). Let \(m\) be the integer such that the projection of \(x_2\) onto \(\R e_1\) lies within \(A_2 = \hv{te_1:0\leq\sgn\h{m}t\leq\abs{m}}\). 
			If \(\mathbb{Z}e_1 = \Gamma\), we are done, else we can find an \(x_2\in\Gamma\backslash\mathbb{Z}e_1\). Then there must exist some \(m\in\mathbb{Z}\) such that the projection of \(x_2\) onto \(\R e_1\) lies within \(A_1 = \hv{te_1:\ t\in\R,\ 0 \leq t\leq m}\). Now let \(\Delta_2\) denote the set of points whose projections onto \(\R e_1\) also lie in \(A_2\) and whose distance to \(A_2\) is smaller than that of \(x_2\), see Figure~\ref{fig: lattice cylinder}.
			\begin{figure}
				\centering
				\includegraphics{img/Lattice.pdf}
				\caption{A plot of a Lattice with the dots representing the lattice points. Shown are the already chosen vector \(e_1\) and the line \(\R e_1\) this generates, which is drawn with a dashed line. An arbitrary point \(x_2\in\Gamma\backslash\R e_1\) is chosen, for which \(A_2\)  is drawn in red and \(\Delta_2\) as the shaded area. We can see that this contains finite points, and one point in \(\Gamma\backslash\R e_1\) closest to \(\R e_1\) is marked as \(e_2\). Remark that this choice is not unique.}
				\label{fig: lattice cylinder}
			\end{figure}
			Remark that this set has some finite volume and thus contains finite points of \(\Gamma\) as we discussed above. We can therefore choose come \(e_2\) in \(\Delta_2\) which is closest to \(\R e_1\) but not on it, remark that this choice is not unique. We now want to show that \(\mathbb{Z}e_1 + \mathbb{Z}e_2 = \h{\R e_1 + \R e_2}\cap\Gamma\). Suppose that this is not true, we can then find an \(u_2\in\h{\Gamma\cap\h{\R e_1 + \R e_2}}\backslash\h{\mathbb{Z}e_1 + \mathbb{Z}e_2}\). Remark that there exist \(m_1,m_2\in\mathbb{Z}\) such that \(u_2\in\hv{\h{m_1 + t}e_1 + \h{m_2 + s}e_2:t,s\in\h{0,1}}\), i.e. there exist some \(t,s\in\h{0,1}\) and \(m_1,m_2\in\mathbb{Z}\) such that \(u_1 = \h{m_1 + t}e_1 + \h{m_2 + s}e_2\). It follows that the distance from \(u_1 - m_1e_1 - m_2e_2\) would be closer to \(\R e_1\) than \(e_2\) and we can move this vector to one in \(\Delta_2\) by adding some multiple of \(e_1\) while not changing the distance to \(\R e_1\). This would lead to a contradiction with the construction of \(e_2\) and we can therefore conclude that \(\mathbb{Z}e_1 + \mathbb{Z}e_2 = \Gamma\cap\h{\R e_1 + \R e_2}\). 
				
			Again if this covers the whole of \(\Gamma\), we would be done, else we can repeat the process but look for a linearly independent vector closest to a higher dimensional plane, i.e. \(e_3\) would be the closest point to \(\R e_1 + \R e_2\) and \(e_4\) would be closest to \(\R e_1 + \R e_2 + \R e_3\), etc. We iterate this process to get a set \(\hv{e_1,\ldots, e_k}\). As this is a set of independent vectors, this process must terminate as the dimension of \(\R[n]\) is finite. Thus we conclude that there must exist some \(0\leq k\leq n\) and a basis \(\hv{e_1,\ldots, e_k}\) for \(\Gamma\).
			
			Using this basis, we will generate a diffeomorphism between \(\mathbb{T}^k\times\R[n - k]\) and \(\m_c\). This diffeomorphism should make the diagram in Figure~\ref{fig: cd flow} commute. To show the existence of this diffeomorphism, we must of course first define the functions \(\rho\) and \(F\).
			
			Let us first define \(\rho:\R[n]\to\mathbb{T}^k\times\R[n - k]\). Remark that we can write a vector \(v\in\R[n]\) as a vector \(v = \h{\phi,y}\in\R[k]\times\R[n - k]\). Notice that we have a surjective mapping \(\tilde{\rho}:\R[k]\to\mathbb{T}^k\) given by
			\begin{equation*}
				\tilde{\rho}\h{\phi_1,\ldots,\phi_k} = \h{\phi_1\mod 1,\ldots,\phi_k\mod 1}.
			\end{equation*}
			Remark that this function is well-defined as \(S^1\) is diffeomorphic to \(\R/\mathbb{Z}\). This mapping lets us define a mapping \(\rho:\R[n]\to\mathbb{T}^k\times\R[n - k]:\h{\phi,y}\mapsto\h{\tilde{\rho}\h{\phi},y}\). Remark that \(\rho\) is a local diffeomorphism.
			
			Next up, we can go on and define \(F\). First, we choose the standard basis for \(\R[n]\) and denote it as \(\beta = \hv{f_1,\ldots, f_n}\). Let \(\hv{e_1,\ldots,e_n}\) denote an extension of the basis \(\hv{e_1,\ldots,e_k}\) of \(\Gamma\) with vectors from \(\beta\), see \cite[Theorem 1.10]{Friedberg2003}. Remark that the first \(k\) vectors in this basis are still the basis for \(\Gamma\). We can then define a linear mapping \(F\) as the basis transformation \(F\h{f_i} = e_i\). By definition, this mapping is bijective and as it is linear also a diffeomorphism. 
			
			Using Theorem 4.30 in \cite{Lee2013}, we can show that there must exist a diffeomorphism \(\tilde{F}\) which makes the diagram in Figure~\ref{fig: cd flow} commute. First of all, remark that \(\rho\) and \(\gposflow{p_0}\) are smooth submersions as they are both local diffeomorphisms, see \cite[Proposition 4.8]{Lee2013}. The existence of smooth maps \(\tilde{F}\) and \(\tilde{F}^{-1}\) with the properties that \(\tilde{F}\circ\rho = \gposflow{p_0}\circ F\) and \(\tilde{F}^{-1}\circ\gposflow{p_0} = \rho\circ F^{-1}\) is then a consequence of the fact that the definition of \(F\) implies that \(\gposflow{p_0}\circ F\) and \(\rho\circ F^{-1}\) are constant on the fibres of respectively \(\rho\) and \(\gposflow{p_0}\). We now have to show that \(\tilde{F}^{-1}\) is indeed the inverse of \(\tilde{F}\), here we will use that \(\rho\) and \(\gposflow{p_0}\) are surjective such that they both have a right inverse, which we denote with \(\rho^{-1}\) and \(\h{\gposflow{p_0}}^{-1}\). We can see that \(\tilde{F}^{-1}\) is the right inverse of \(\tilde{F}\) using the property that they make the diagram of Figure~\ref{fig: cd flow} commute. 
			\begin{align*}
				\tilde{F}\circ\tilde{F}^{-1}
				&= \tilde{F}\circ\tilde{F}^{-1}\circ\gposflow{p_0}\circ\h{\gposflow{p_0}}^{-1} = \tilde{F}\circ\rho\circ F\circ\h{\gposflow{p_0}}^{-1}\\
				&= \gposflow{p_0}\circ F^{-1}\circ F\circ\h{\gposflow{p_0}}^{-1} = \id_{\m_c}.
			\end{align*}
			Similarly, we can deduce that \(\tilde{F}^{-1}\) is the left inverse of \(\tilde{F}\).
			\begin{equation*}
				\tilde{F}^{-1}\circ\tilde{F} = \tilde{F}^{-1}\circ\tilde{F}\circ\rho\circ\rho^{-1} = \tilde{F}^{-1}\circ\gposflow{p_0}\circ F^{-1}\circ\rho^{-1} = \rho\circ F\circ F^{-1}\circ\rho^{-1} = \id_{\mathbb{T}^k\times\R[n - k]}.
			\end{equation*}
			Hence, it follows that there exists a diffeomorphism \(\tilde{F}\) between \(\mathbb{T}^k\times\R[n - k]\) and \(\m_c\). Now remark that \(\m_c\) is compact, implying that \(n = k\) which was the result we wanted.
			\begin{figure}
				\centering
				\includegraphics{./img/CommutativeDiagram_Flow.pdf}
				\caption{Commutative diagram which describes the relation between \(F:\R[n]\to\R[n]\) and \(\tilde{F}:\mathbb{T}^{k}\times\R[n - k]\) by the natural mapping \(\rho\) and the simultaneous flow \(\gposflow{p_0}\).}
				\label{fig: cd flow}
			\end{figure}
 		\end{proof}
 		This shows that the trajectories of the integrable system all lie on \(\m_c\) and that this space is homeomorphic to some torus. Furthermore, the maps in this proof let us define coordinates on \(\m_c\) such that our simultaneous flow is of a simple form.
 		\begin{corollary}\label{cor: angle coordinates}
 			There exists a chart on a compact and connected	\(\m_c\) such that the flows of the first integrals are linear.
		\end{corollary}
		\begin{proof}
			Let \(\h{\m,\omega,f}\) be an integrable system and let \(\m_c\) be compact and connected. Define \(F,\rho\) and \(\tilde{F}\) as in the proof of Theorem~\ref{thm: level set donut}. Let us now consider the function \((\gposflow{p_0}\circ F)^{-1}\), where \(p_0\in\m_c\). We can define a chart around \(p_0\) as \(\gposflow{p_0}\) is a local diffeomorphism. The representation of \(\gflow\) in these coordinates can be determined using the bases \(f_i\) and \(e_i\) for \(\R[n]\) as defined in the proof of Theorem~\ref{thm: level set donut}
			\begin{equation*}
				\h{F^{-1}\circ\h{\gposflow{p_0}}^{-1}\circ \gtimeflow{t}\circ \gposflow{p_0}\circ F}\h{\sum_i\phi_if_i} F^{-1}\h{\sum_i\phi_ie_i + t} = \sum_i\phi_if_i + F^{-1}\h{t}.
			\end{equation*}
			Hence, the flows of the first integrals are all linear. From this, we can easily deduce that the flow associated with a first integral is linear.
		\end{proof}
		These coordinates are what we call \textbf{angle coordinates} as they correspond to the angles on the torus. These angle coordinates give a representation on \(\m_c\), but not on the whole of \(\m\). We want to extend these angle coordinates to coordinates on \(\m\) in a natural manner.
		\begin{theorem}\label{thm: arn liou}
			Let \(\h{\m,\omega,f}\) be an integrable system and suppose that \(\m_c\) is compact and connected. Then there exist Darboux coordinates \(\symbas{\phi}{\psi}\), called the \textbf{action-angle coordinates}, such that \(\h{\phi_i}\) are the angle coordinates described in Corollary~\ref{cor: angle coordinates} and \(\h{\psi_i}\) are some first integrals.
		\end{theorem}
		We will now go over the proof of this theorem here, but it can be found in \cites{Arnold1989, Heckman2014, Duistermaat1980}. The most important consequence of the proof given in \cite{Arnold1989} is the fact that we can solve an integrable system using quadratures. This goes to show that any integrable system hence has a somewhat `nice' solution. Let us consider a relevant physical problem: two bodies attracted by gravity, also called the Kepler problem. We will show that this system is actually an integrable system.
		\begin{example}
			\input{example/kepler.tex}
		\end{example}
\end{document}